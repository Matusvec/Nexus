# Nexus Backend API Specification

This document defines the FastAPI endpoints that the frontend expects. Implement these endpoints in your backend to connect the frontend.

## Base URL
```
http://localhost:8000
```

---

## üìÑ Documents

### Upload Document
```http
POST /upload
Content-Type: multipart/form-data
```

**Request Body:**
- `file`: File (PDF, DOCX, TXT, MD)
- `group_id`: string (optional) - Assign to a specific group

**Response:**
```json
{
  "id": "doc_abc123",
  "filename": "example.pdf",
  "uploadedAt": "2026-01-28T10:30:00Z",
  "fileSize": 2456000,
  "chunkCount": 45,
  "status": "ready",
  "summary": "Document summary generated by LLM..."
}
```

**Status Codes:**
- `200` - Success
- `400` - Invalid file type
- `500` - Processing error

---

### List Documents
```http
GET /documents
```

**Query Parameters:**
- `group_id`: string (optional) - Filter by group
- `status`: string (optional) - Filter by status (ready, processing, error)
- `limit`: int (default: 50)
- `offset`: int (default: 0)

**Response:**
```json
[
  {
    "id": "doc_abc123",
    "filename": "example.pdf",
    "uploadedAt": "2026-01-28T10:30:00Z",
    "fileSize": 2456000,
    "chunkCount": 45,
    "status": "ready",
    "summary": "...",
    "groupId": "group_xyz"
  }
]
```

---

### Get Document Details
```http
GET /documents/{document_id}
```

**Response:**
```json
{
  "id": "doc_abc123",
  "filename": "example.pdf",
  "uploadedAt": "2026-01-28T10:30:00Z",
  "fileSize": 2456000,
  "chunkCount": 45,
  "status": "ready",
  "summary": "...",
  "groupId": "group_xyz",
  "raptorTree": {
    "layers": 3,
    "nodesByLayer": {
      "0": 45,
      "1": 12,
      "2": 3
    }
  }
}
```

---

### Delete Document
```http
DELETE /documents/{document_id}
```

**Response:**
```json
{
  "success": true,
  "message": "Document deleted successfully"
}
```

---

### Get Document Chunks
```http
GET /documents/{document_id}/chunks
```

**Query Parameters:**
- `layer`: int (optional) - Filter by RAPTOR layer

**Response:**
```json
[
  {
    "id": "chunk_001",
    "documentId": "doc_abc123",
    "content": "This is the chunk text content...",
    "layer": 0,
    "contentType": "text",
    "metadata": {
      "pageNumber": 1,
      "imageRefs": [],
      "parentIds": ["chunk_100"],
      "childIds": []
    }
  }
]
```

---

### Build RAPTOR Tree
```http
POST /documents/{document_id}/build-tree
```

**Response:**
```json
{
  "success": true,
  "layers": 3,
  "totalNodes": 60,
  "buildTime": 12.5
}
```

---

## üîç Query

### Query Knowledge Base
```http
POST /query
Content-Type: application/json
```

**Request Body:**
```json
{
  "question": "What is RAPTOR retrieval?",
  "document_id": "doc_abc123",    // optional - filter to specific doc
  "group_id": "group_xyz",         // optional - filter to specific group
  "top_k": 10,                     // optional - number of chunks to retrieve
  "persona_id": "max"              // optional - which AI persona to use
}
```

**Response:**
```json
{
  "answer": "RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) is a hierarchical approach to RAG systems that builds a tree structure of document summaries...",
  "sources": [
    {
      "documentId": "doc_abc123",
      "documentName": "RAPTOR_Paper.pdf",
      "chunkId": "chunk_001",
      "content": "The relevant chunk content...",
      "layer": 0,
      "relevanceScore": 0.92
    }
  ],
  "queryType": "complex",
  "tokensUsed": 1250
}
```

---

### Stream Query (for chat interface)
```http
POST /query/stream
Content-Type: application/json
```

**Request Body:** Same as `/query`

**Response:** Server-Sent Events (SSE)
```
data: {"type": "token", "content": "RAPTOR"}
data: {"type": "token", "content": " is"}
data: {"type": "token", "content": " a"}
...
data: {"type": "sources", "sources": [...]}
data: {"type": "done"}
```

---

## üìÅ Groups

### List Groups
```http
GET /groups
```

**Response:**
```json
[
  {
    "id": "group_xyz",
    "name": "Mechanical Engineering",
    "description": "CAD files and motor specs",
    "color": "#F97316",
    "documentIds": ["doc_1", "doc_2"],
    "position": {"x": 100, "y": 100},
    "assignedPersona": "max"
  }
]
```

---

### Create Group
```http
POST /groups
Content-Type: application/json
```

**Request Body:**
```json
{
  "name": "New Group",
  "description": "Group description",
  "color": "#3B82F6",
  "position": {"x": 200, "y": 200},
  "assignedPersona": "elena"
}
```

**Response:** Created group object

---

### Update Group
```http
PATCH /groups/{group_id}
Content-Type: application/json
```

**Request Body:**
```json
{
  "name": "Updated Name",
  "position": {"x": 300, "y": 150}
}
```

**Response:** Updated group object

---

### Delete Group
```http
DELETE /groups/{group_id}
```

---

### Add Document to Group
```http
POST /groups/{group_id}/documents
Content-Type: application/json
```

**Request Body:**
```json
{
  "document_id": "doc_abc123"
}
```

---

## ü§ñ Human Tasks

### List Human Tasks
```http
GET /tasks
```

**Query Parameters:**
- `status`: string (optional) - pending, in-progress, completed, cancelled

**Response:**
```json
[
  {
    "id": "task_001",
    "type": "measurement",
    "title": "Measure shaft diameter",
    "instructions": [
      "Grab your calipers (¬±0.01mm accuracy)",
      "Measure at 3 points along the length",
      "Take a photo showing the reading"
    ],
    "safetyWarnings": ["Deburr sharp edges first"],
    "expectedOutput": "CSV file with measurements",
    "status": "pending",
    "createdAt": "2026-01-28T10:30:00Z"
  }
]
```

---

### Complete Human Task
```http
POST /tasks/{task_id}/complete
Content-Type: multipart/form-data
```

**Request Body:**
- `files`: File[] (optional) - Uploaded result files

**Response:**
```json
{
  "id": "task_001",
  "status": "completed",
  "completedAt": "2026-01-28T11:45:00Z",
  "uploadedFiles": [
    {
      "id": "file_001",
      "name": "measurement.csv",
      "type": "text/csv",
      "size": 1234,
      "url": "/files/file_001"
    }
  ]
}
```

---

## üìä Statistics

### Get Database Stats
```http
GET /stats
```

**Response:**
```json
{
  "totalDocuments": 15,
  "totalChunks": 450,
  "chunksByLayer": {
    "0": 350,
    "1": 80,
    "2": 20
  },
  "documents": [
    {
      "id": "doc_1",
      "name": "example.pdf",
      "chunkCount": 45
    }
  ]
}
```

---

## üí¨ Conversations

### Create Conversation
```http
POST /conversations
Content-Type: application/json
```

**Request Body:**
```json
{
  "persona_id": "max"
}
```

**Response:**
```json
{
  "id": "conv_abc123"
}
```

---

### Get Conversation History
```http
GET /conversations/{conversation_id}
```

**Response:**
```json
{
  "id": "conv_abc123",
  "messages": [
    {
      "role": "user",
      "content": "What's the torque spec?",
      "timestamp": "2026-01-28T10:30:00Z"
    },
    {
      "role": "assistant",
      "content": "Based on the motor datasheet...",
      "timestamp": "2026-01-28T10:30:05Z"
    }
  ]
}
```

---

## üîß Implementation Notes

### FastAPI Example Structure

```python
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, List

app = FastAPI(title="Nexus API", version="1.0.0")

# CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models
class QueryRequest(BaseModel):
    question: str
    document_id: Optional[str] = None
    group_id: Optional[str] = None
    top_k: int = 10
    persona_id: Optional[str] = None

class QueryResponse(BaseModel):
    answer: str
    sources: List[dict]
    queryType: str
    tokensUsed: int

# Endpoints
@app.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    group_id: Optional[str] = None
):
    # 1. Save file
    # 2. Parse document
    # 3. Chunk text
    # 4. Generate embeddings
    # 5. Store in ChromaDB
    # 6. Build RAPTOR tree
    pass

@app.post("/query", response_model=QueryResponse)
async def query_knowledge_base(request: QueryRequest):
    # 1. Classify query type
    # 2. Retrieve relevant chunks using RAPTOR
    # 3. Generate answer with LLM
    # 4. Return with sources
    pass

@app.post("/query/stream")
async def stream_query(request: QueryRequest):
    async def generate():
        # Yield tokens as SSE
        yield f"data: {json.dumps({'type': 'token', 'content': 'Hello'})}\n\n"
    return StreamingResponse(generate(), media_type="text/event-stream")
```

### Environment Variables

```env
# .env file
GEMINI_API_KEY=your_api_key
CHROMA_PERSIST_DIR=./chroma_db
EMBEDDING_MODEL=gemini-embedding-001
GENERATION_MODEL=gemini-2.0-flash-exp
```

---

## üîó Frontend Integration

The frontend is configured to proxy API requests:

```javascript
// next.config.js
async rewrites() {
  return [
    {
      source: '/api/:path*',
      destination: 'http://localhost:8000/:path*',
    },
  ];
}
```

So frontend calls to `/api/documents` will be proxied to `http://localhost:8000/documents`.

Alternatively, set the `NEXT_PUBLIC_API_URL` environment variable:
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```
